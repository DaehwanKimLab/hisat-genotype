#!/usr/bin/env python
# --------------------------------------------------------------------------- #
# Copyright 2017, Daehwan Kim <infphilo@gmail.com>                            #
#                                                                             #
# This file is part of HISAT-genotype. The purpose of this script is to wrap  #
# the main functions if HISAT-genotype into a usable pipeline.                #
#                                                                             #
# HISAT-genotype is free software: you can redistribute it and/or modify      #
# it under the terms of the GNU General Public License as published by        #
# the Free Software Foundation, either version 3 of the License, or           #
# (at your option) any later version.                                         #
#                                                                             #
# HISAT-genotype is distributed in the hope that it will be useful,           #
# but WITHOUT ANY WARRANTY; without even the implied warranty of              #
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the               #
# GNU General Public License for more details.                                #
#                                                                             #
# You should have received a copy of the GNU General Public License           #
# along with HISAT-genotype.  If not, see <http://www.gnu.org/licenses/>.     #
# --------------------------------------------------------------------------- #

import sys
import os
import subprocess
import re
import datetime
import traceback
import glob
import multiprocessing
import random
import hisatgenotype_args as arguments
import hisatgenotype_typing_common as typing_common

from datetime import datetime, date, time
from argparse import ArgumentParser, FileType
from hisatgenotype_typing_core import genotyping_locus
from hisatgenotype_typing_process import extract_reads, extract_vars

# --------------------------------------------------------------------------- #
# Auxillary functions for wraper script                                       #
# --------------------------------------------------------------------------- #
""" Build Namespace to hold combine set of Arguments: Necessary due to arg """
class Namespace:
    def __init__(self, **kwargs):
        self.__dict__.update(kwargs)
    
    def __repr__(self):
        keys = sorted(self.__dict__)
        items = ("{}={!r}".format(k, self.__dict__[k]) for k in keys)
        return "{}({})".format(type(self).__name__, ", ".join(items))

    def __eq__(self, other):
        return self.__dict__ == other.__dict__

""" Initialize Global lock for use with multithread processes """
def init(l):
    global lock
    lock = l

l = multiprocessing.Lock()


# --------------------------------------------------------------------------- #
# Base functions to ensuring proper files are present for HISATgenotype       #
# --------------------------------------------------------------------------- #
""" Make sure the base files are present """
def check_base(base_fname, aligner):
    genotype_fnames = ["%s.fa" % base_fname,
                       "%s.locus" % base_fname,
                       "%s.snp" % base_fname,
                       "%s.haplotype" % base_fname,
                       "%s.link" % base_fname,
                       "%s.coord" % base_fname,
                       "%s.clnsig" % base_fname]
    # graph index files
    if aligner == "hisat2":
        genotype_fnames += ["%s.%d.ht2" % (base_fname, i+1) for i in range(8)]
    else:
        assert aligner == "bowtie2"
        genotype_fnames = ["%s.%d.bt2" % (base_fname, i+1) for i in range(4)]
        genotype_fnames += ["%s.rev.%d.bt2" % (base_fname, i+1) for i in range(2)]
        
    if not typing_common.check_files(genotype_fnames):        
        return False
    
    return True

""" Extract Variants from hisatgenotype database """
def run_vars(base_fname,
            threads,
            locus_list,
            inter_gap,
            intra_gap,
            whole_haplotype,
            min_var_freq,
            ext_seq_len,
            leftshift,
            partial,
            verbose):
    # Clone hisatgenotype database from git
    if not os.path.exists("hisatgenotype_db"):
        typing_common.clone_hisatgenotype_database()
    
    if not base_fname:
        base_fname = []
        for database in os.listdir("hisatgenotype_db"):
            if database in ['.git', 'README.md']:
                continue
            base_fname.append(database.lower())

    pool = multiprocessing.Pool(int(threads), initializer=init, initargs=(l,))
    for base in base_fname:
        if base.find('/') != -1:
            elems = base.split('/')
            base = elems[-1]
            base_dname = '/'.join(elems[:-1])
        else:
            base_dname = ""        

        pool.apply_async(extract_vars, 
                         args=(base,
                               base_dname,
                               locus_list,
                               inter_gap,
                               intra_gap,
                               whole_haplotype,
                               min_var_freq,
                               ext_seq_len,
                               leftshift,
                               partial,
                               verbose))
    pool.close()
    pool.join()


# --------------------------------------------------------------------------- #
# Main functions for handling exsisting bam files/alignments                  #
# --------------------------------------------------------------------------- #
""" Need to index the bam file """
def index_bam(bam_fname,
              verbose):
    print("%s Indexing %s ..." % (str(datetime.now()), bam_fname), 
          file=sys.stderr)
    bamindex_cmd = ["samtools",
                    "index",
                    bam_fname]
    if verbose:
        print("\t%s" % ' '.join(bamindex_cmd), 
              file=sys.stderr)
    bamindex_proc = subprocess.call(bamindex_cmd)

""" Builds read file from the SAM lines that overlap the locus regions """
def reads_from_bam(bam_fname,
                   out_read_dname,
                   chr,
                   left,
                   right,
                   read_base_fname, # sample => sample.1.fq.gz and sample.2.fq.gz
                   paired,
                   fastq,
                   verbose):

    lock.acquire()
    if not os.path.exists(out_read_dname):
        os.mkdir(out_read_dname)
    lock.release()
        
    read_fnames = []
    if paired:
        read_fnames = [out_read_dname + "/" + read_base_fname + "-extracted-1.fq.gz",
                       out_read_dname + "/" + read_base_fname + "-extracted-2.fq.gz"]
    else:
        read_fnames = [out_read_dname + "/" + read_base_fname + "-extracted.fq.gz"]

    if paired:
        gzip1_proc = subprocess.Popen(["gzip"],
                                      stdin=subprocess.PIPE,
                                      stdout=open(read_fnames[0], 'w'),
                                      stderr=open("/dev/null", 'w'))

        gzip2_proc = subprocess.Popen(["gzip"],
                                      stdin=subprocess.PIPE,
                                      stdout=open(read_fnames[1], 'w'),
                                      stderr=open("/dev/null", 'w'))
    else:
        gzip1_proc = subprocess.Popen(["gzip"],
                                      stdin=subprocess.PIPE,
                                      stdout=open(read_fnames[0], 'w'),
                                      stderr=open("/dev/null", 'w'))

    def write_read(gzip_proc, read_name, seq, qual):
        if fastq:
            gzip_proc.stdin.write("@%s\n" % read_name)
            gzip_proc.stdin.write("%s\n" % seq)
            gzip_proc.stdin.write("+\n")
            gzip_proc.stdin.write("%s\n" % qual)
        else:
            gzip_proc.stdin.write(">%s\n" % prev_read_name)
            gzip_proc.stdin.write("%s\n" % seq)                    

    bamview_cmd = ["samtools", 
                   "view", 
                   bam_fname, 
                   "%s:%d-%d" % (chr, left+1, right+1)]
    if verbose:
        print("\t%s" % ' '.join(bamview_cmd), file=sys.stderr)
    bamview_proc = subprocess.Popen(bamview_cmd,
                                    stdout=subprocess.PIPE,
                                    stderr=open("/dev/null", 'w'))

    sort_read_cmd = ["sort", "-k", "1,1", "-s"] # -s for stable sorting
    alignview_proc = subprocess.Popen(sort_read_cmd,
                                      stdin=bamview_proc.stdout,
                                      stdout=subprocess.PIPE,
                                      stderr=open("/dev/null", 'w'))

    prev_read_name, extract_read, read1, read2 = "", False, [], []
    for line in alignview_proc.stdout:
        if line.startswith('@'):
            continue
        line = line.strip()
        cols = line.split()
        read_name, flag, chr, pos, mapQ, cigar, _, _, _, read, qual = cols[:11]
        flag, pos = int(flag), int(pos)
        strand = '-' if flag & 0x10 else '+'                   
        AS, NH = "", ""
        for i in range(11, len(cols)):
            col = cols[i]
            if col.startswith("AS"):
                AS = int(col[5:])
            elif col.startswith("NH"):
                NH = int(col[5:])

        if NH == 1:
            extract_read = True

        if flag & 0x40 or not paired:   # left read
            if not read1:
                if flag & 0x10:         # reverse complement
                    read1 = [typing_common.reverse_complement(read), qual[::-1]]
                else:
                    read1 = [read, qual]
        else:
            assert flag & 0x80          # right read
            if flag & 0x10:             # reverse complement
                read2 = [typing_common.reverse_complement(read), qual[::-1]]
            else:
                read2 = [read, qual]

    if extract_read:
        if paired:
            if len(read1) == 2 and len(read2) == 2:
                write_read(gzip1_proc, prev_read_name, read1[0], read1[1])
                write_read(gzip2_proc, prev_read_name, read2[0], read2[1])
        else:                    
            write_read(gzip1_proc, prev_read_name, read1[0], read1[1])

    gzip1_proc.stdin.close()
    if paired:
        gzip2_proc.stdin.close()

    return read_fnames  

""" Extract reads from BAM alignment files in range of locus """
def extract_bam(file_lists,
                base,
                out_dir,
                target_locus_list,
                fastq,
                paired,
                alignment_fname,
                aligner,
                verbose):
    # variants, backbone sequence, and other sequeces
    if not check_base(base, aligner):
        print("Error: some of the base files are missing!", 
              file=sys.stderr)
        sys.exit(1)

    # Read locus alleles (names and sequences)
    regions, region_loci = {}, {}
    for line in open("%s.locus" % base):
        family, allele_name, chr, left, right = line.strip().split()[:5]
        family = family.lower()
        if len(target_locus_list) > 0 \
                and family not in target_locus_list:
            continue
        
        locus_name = allele_name.split('*')[0]
        if family in target_locus_list \
                and len(target_locus_list[family]) > 0 \
                and locus_name not in target_locus_list[family]:
            continue
        
        left, right = int(left), int(right)
        if family not in region_loci:
            region_loci[family] = []
        region_loci[family].append([locus_name, allele_name, chr, left, right])

    if len(region_loci) <= 0:
        print("Warning: no loci exists!", file=sys.stderr)
        sys.exit(1)

    # Sort the BAM file
    assert alignment_fname != "" and os.path.exists(alignment_fname)
    if not os.path.exists(alignment_fname + ".bai"):
        index_bam(alignment_fname,
                  verbose)
    assert os.path.exists(alignment_fname + ".bai")

    # Extract reads and perform genotyping
    for family, loci in region_loci.items():
        for locus_name, allele_name, chr, left, right in loci:
            out_read_fname = "%s.%s" % (family, locus_name)
            if verbose:
                print("\tExtracting reads beloning to %s-%s ..." % \
                    (family, locus_name), file=sys.stderr)

            extracted_read_fnames = reads_from_bam(alignment_fname,
                                                   out_dir,
                                                   chr,
                                                   left,
                                                   right,
                                                   out_read_fname,
                                                   paired,
                                                   fastq,
                                                   verbose)

        lock.acquire()
        if family not in file_lists:
            file_lists.update({ family : [] })
        file_lists[family].append(out_read_fname)
        lock.release() 

        print("\n", file=sys.stderr)


# --------------------------------------------------------------------------- #
# Main function for typing. Requires all arguments in a Namespace that can    #
# be parsed                                                                   #
# --------------------------------------------------------------------------- #
def typing_process(args):
    """ Set-up: Everything in section is required """
    # Begin parsing bases and locus lists into a single variable: region_list
    region_list = {}
    if args.base_fname != "":
        args.base_fname = args.base_fname.lower().split(',') 
    else:
        args.base_fname = [] 

    if args.locus_list != "" :
        args.locus_list = args.locus_list.upper().split(';') 
    else: 
        args.locus_list = []

    if (len(args.base_fname) != len(args.locus_list)) and args.locus_list:
        print("Error: --base and --locus-list not correct format \
                    (ex. --base hla,rbg --locus-list A,B,C;ABO,RHD)", 
              file=sys.stderr)
        exit(1)

    for itr in range(len(args.base_fname)):
        family = args.base_fname[itr]

        if args.locus_list:
            loci_names = args.locus_list[itr].split(',')
        else:
            loci_names = []

        region_list.update({ family : loci_names })
    
    # Confirm correct aligner and set block_size
    if args.aligner not in ["hisat2", "bowtie2"]:
        print("Error: --aligner should be either hisat2 or bowtie2.", 
              file=sys.stderr)
        sys.exit(1)        
    block_size = 20000000 if args.extract_whole else 0

    # set only_locus_list filter for extracting the database 
    # (used in typing_common.extract_database_if_not_exists)
    if args.only_locus_list == "":
        only_locus_list = []
    else:
        if len(args.base_fname) != 1:
            only_locus_list = args.only_locus_list.split(',')

    if args.verbose and args.verbose_level == 0:
        args.verbose_level = 1

    # Parse debug options and parameters
    debug = {}
    debug_opts = ["basic", "full", "pair", "test_list", "test_id", "single-end"]
    if args.debug != "":
        for item in args.debug.split(','):
            if ':' in item:
                fields = item.split(':')
                assert len(fields) >= 2
                key, value = fields[0], ':'.join(fields[1:])
                debug[key] = value
            else:
                debug[item] = 1
        for item in debug:
            if item not in debug_opts:
                print("Warning: %s not valid option for debug" % item, 
                      file=sys.stderr)
                exit(1)
            else:
                continue

    # Advanced setting alerts for users
    if not args.partial:
        print("Warning: --no-partial should be used for debugging purpose only.",
              file=sys.stderr)

    if args.read_len * 2 > args.fragment_len:
        print("Warning: fragment might be too short (%d)" % (args.fragment_len), 
              file=sys.stderr)

    skip_fragment_regions = []
    if args.skip_fragment_regions != "":
        prev_left, prev_right = -1, -1
        for region in args.skip_fragment_regions.split(','):
            left, right = region.split('-')
            left, right = int(left), int(right)
            assert left < right
            assert prev_right < left
            prev_left, prev_right = left, right
            skip_fragment_regions.append([left, right])

    # Set display alleles for assembly
    if args.display_alleles == "":
        display_alleles = []
    else:
        display_alleles = args.display_alleles.split(',')

    # Critical since this will preserve the input files 
    # after bypass of read extraction
    if args.already_extract:
        args.keep_extract = True

    # Set default output and make final changes before beginning
    if args.out_dir == "":
        args.out_dir = os.getcwd()
        args.out_dir += "/hisatgenotype_out"

    if not os.path.exists(args.out_dir):
        os.makedirs(args.out_dir)

    if args.read_dir:
        if '/' != args.read_dir[-1]:
            args.read_dir += '/'

    
    """ Read Extraction: Optional selection performed by default """
    is_bam, single_run = False, False
    read_fnames, fq_fname_base = [], {}
    if args.debug == "":
        if args.read_fname_U != "":
            read_fnames = ['%s%s' % (args.read_dir, args.read_fname_U)]
            single_run = True
        elif args.read_fname_1 != "" or args.read_fname_2 != "":
            if args.read_fname_1 == "" or args.read_fname_2 == "":
                print("Error: please specify both -1 and -2.", 
                      file=sys.stderr)
                sys.exit(1)
            read_fnames = ['%s%s' % (args.read_dir, args.read_fname_1), 
                           '%s%s' % (args.read_dir, args.read_fname_2)]
            single_run = True
        elif args.alignment_fname != "":
            alignment_fnames = ['%s%s' % (args.read_dir, args.alignment_fname)]
            is_bam = True
        else:
            if args.read_dir == '' or not os.path.exists(args.read_dir):
                print("Error: please specify read file names correctly: \
                            -U or -1 and -2 or --bamfile or --read-dir",
                      file=sys.stderr)
                sys.exit(1)
            alignment_fnames = glob.glob("./%s/*.bam" % (args.read_dir))
            is_bam = True if alignment_fnames else False

        if args.read_fname_U != "":
            paired = False
            args.discordant = True
        else:
            paired = args.paired
            if (args.read_fname_1 != "" and args.read_fname_2 != "") \
                    and not paired:
                print("Error: Don't set --single-end when using -1 and -2 \
                            options.",
                      file=sys.stderr)
                exit(1)

        if not args.already_extract:
            # Geno_genome is only needed for extract reads
            if args.genotype_genome != '':
                geno_genome = args.genotype_genome 
            else:
                geno_genome = 'genotype_genome'

            if not is_bam:
                job_range = []
                for num in args.job_range.split(','):
                    job_range.append(int(num))

                fq_fname_base = extract_reads(geno_genome,
                                              args.base_fname,
                                              "" if single_run else args.read_dir,
                                              args.out_dir,
                                              args.suffix,
                                              read_fnames,
                                              args.fastq,
                                              paired,
                                              args.simulation,
                                              args.threads,
                                              args.threads_aprocess,
                                              args.max_sample,
                                              job_range,
                                              args.aligner,
                                              block_size,
                                              args.verbose)
            else:
                pool = multiprocessing.Pool(int(args.threads), 
                                            initializer=init, 
                                            initargs=(l,))
                for bam_file in alignment_fnames:
                    pool.apply_async(extract_bam,
                                    args = (fq_fname_base,
                                            geno_genome,
                                            args.out_dir,
                                            region_list,
                                            args.fastq,
                                            args.paired,
                                            args.alignment_fname,
                                            args.aligner,
                                            args.verbose))
                pool.close()
                pool.join()
        else:
            _, _, filename_base = typing_common.get_filename_match(read_fnames)
            for base in args.base_fname:
                fq_fname_base[base] = filename_base

        assert fq_fname_base

    """ Genotyping: Core of HISATgenotype """
    if ',' not in args.aligner and '.' not in args.aligner:
        if args.graph_index:
            args.aligner += '.graph'
        else:
            args.aligner += '.linear'
    args.aligner = args.aligner.split(',')
    for i in range(len(args.aligner)):
        args.aligner[i] = args.aligner[i].split('.')

    if args.build_index:
        run_vars(args.base_fname,
                args.threads,
                [], # Empty Locus-list
                args.inter_gap,
                args.intra_gap,
                args.whole_haplotype,
                args.min_var_freq,
                args.ext_seq_len,
                args.leftshift,
                args.partial,
                args.verbose)

    if not region_list:
        region_list.update({ "ALL" : "ALL" })
    discard_list = set()
    random.seed(args.random_seed)
    if not fq_fname_base:
        if args.debug == '':
            print("No --debug or -U -1 -2 --in-dir options set", 
                  file=sys.stderr)
            exit(1)

        for base, loci in region_list.items():
            if base == "ALL":
                base, loci = [], []
            genotyping_locus(base,
                             loci if not only_locus_list else only_locus_list,
                             args.genotype_genome,
                             only_locus_list,
                             args.partial,
                             args.aligner,
                             read_fnames,
                             args.fastq,
                             args.alignment_fname,
                             args.threads,
                             args.simulate_interval,
                             args.read_len,
                             args.fragment_len,
                             args.best_alleles,
                             args.num_editdist,
                             args.perbase_errorrate,
                             args.perbase_snprate,
                             skip_fragment_regions,
                             args.assembly,
                             args.output_base,
                             args.error_correction,
                             args.keep_alignment,
                             args.discordant,
                             args.type_primary_exons,
                             args.remove_low_abundance_alleles,
                             display_alleles,
                             args.verbose_level,
                             args.assembly_verbose,
                             args.out_dir,
                             debug)
    else:
        log = {} # build log to capture errors
        pool = multiprocessing.Pool(int(args.threads), 
                                    initializer=init, 
                                    initargs=(l,))
        for base, file_list in fq_fname_base.items():
            for fname in file_list:
                entry = base # naming for log

                if args.already_extract:
                    fasta_fname = glob.glob("%s*" % (fname))
                else:
                    fasta_fname = glob.glob("%s/%s*" % (args.out_dir, fname))

                assert len(fasta_fname) < 3, "Too many files found"
                for fn in fasta_fname:
                    entry = entry + ' ' + fn.split('/')[-1]
                    discard_list.add(fn)

                locus_list = region_list[base] if "ALL" not in region_list else []
                log[entry] = pool.apply_async(
                                genotyping_locus,
                                args = (base,
                                        locus_list,
                                        args.genotype_genome,
                                        only_locus_list,
                                        args.partial,
                                        args.aligner,
                                        fasta_fname,
                                        args.fastq,
                                        args.alignment_fname,
                                        args.threads_aprocess,
                                        args.simulate_interval,
                                        args.read_len,
                                        args.fragment_len,
                                        args.best_alleles,
                                        args.num_editdist,
                                        args.perbase_errorrate,
                                        args.perbase_snprate,
                                        skip_fragment_regions,
                                        args.assembly,
                                        args.output_base,
                                        args.error_correction,
                                        args.keep_alignment,
                                        args.discordant,
                                        args.type_primary_exons,
                                        args.remove_low_abundance_alleles,
                                        display_alleles,
                                        args.verbose_level,
                                        args.assembly_verbose,
                                        args.out_dir,
                                        debug)
                                )

        # Generate Log files for errors
        pool.close()

        runtime = str(date.today())
        ofnlog = open("%s_hisat-genotype.log" % (runtime), 'w')        
        
        for entry, x in log.items():
            ofnlog.write('> Base and Files:' + entry + '\n')
            try:
                ofnlog.write(str(x.get()))
            except Exception:
                err_msg = traceback.format_exc()
                ofnlog.write(err_msg)
            ofnlog.write('\n')
        ofnlog.close()
        
        pool.join()
      
    if not args.keep_extract:
        for fname in discard_list:
            os.remove(fname)


# --------------------------------------------------------------------------- #
# Full Wrapper of HISATgenotype to enter script and options                   #
# --------------------------------------------------------------------------- #
if __name__ == '__main__':
    version_dir = '/'.join(os.path.realpath(__file__).split('/')[:-1])
    try:
        h2_v = open(version_dir + "/hisat2/VERSION", "r").read().strip()
        hg_v = open(version_dir + "/VERSION", "r").read().strip()
        version_info = [h2_v, hg_v]
    except:
        version_info = ['', '']

    parser = ArgumentParser(
        description='HISAT-Genotype %s (Built on HISAT2 %s)' \
            % (version_info[1], version_info[0]),
        epilog='See --advanced-help for further options available')

    arguments.args_databases(parser,
                             genome=True) # Add option to change genome name
    arguments.args_aligner_inputs(parser,
                                  keep=True) # Add option to keep alignments

    arguments.args_input_output(parser)                              
    arguments.args_bamfile(parser)

    parser.add_argument('--pass-extract',
                        dest='already_extract',
                        action='store_true',
                        help='Skip read extraction if the read files \
                                input are already extracted by --base'
                        )

    arguments.args_single_end(parser)
    arguments.args_assembly(parser)
    arguments.args_common(parser)

    ### Advanced parser information
    parser_advanced = ArgumentParser(
        description='Advanced Options',
        add_help=False)
    parser_advanced.add_argument('--advanced-help',
                                 action='help',
                                 help='Show Advanced Options')
    parser_advanced.add_argument('--keep-extract',
                                 dest='keep_extract',
                                 action='store_true',
                                 help='Keep extracted fastq read files'
                                 )
    parser_advanced.add_argument('--build-base',
                                 dest='build_index',
                                 action='store_true',
                                 help='Build the indexes listed in --base-fname'
                                 )

    arguments.args_set_aligner(parser_advanced)
    arguments.args_var_gaps(parser_advanced)
    arguments.args_extract_vars(parser_advanced)
    arguments.args_extract_reads(parser_advanced)
    arguments.args_no_partial(parser_advanced)
    arguments.args_locus(parser_advanced)
    parser_advanced.add_argument("--debug",
                                 dest="debug",
                                 type=str,
                                 default="",
                                 help="Test database or code (options: basic, \
                                            pair, full, single-end, test_list,\
                                            test_id)(e.g., test_id:10,basic)"
                                 )

    ## Setup arguments into a new namespace for parsing
    arg_dict, unknown = {}, []
    args2, unused = parser_advanced.parse_known_args()
    args1 = parser.parse_args(unused)
    arg_dict.update(vars(args1))
    arg_dict.update(vars(args2))

    args = Namespace(**arg_dict)

    typing_process(args)
        

